{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction & Data Base Embeddings Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tagore/repos/ai/scripts\")\n",
    "import TextExtractor as te\n",
    "import VectorDB as vdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extractor: Class Definition\n",
    "\n",
    "/scripts/TextExtractor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extractor: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m test_extractor \u001b[38;5;241m=\u001b[39m te\u001b[38;5;241m.\u001b[39mTextExtractor(output, \u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      5\u001b[0m pdfs \u001b[38;5;241m=\u001b[39m test_extractor\u001b[38;5;241m.\u001b[39mget_pdf()\n\u001b[0;32m----> 6\u001b[0m test_extractor\u001b[38;5;241m.\u001b[39mextract_pdf_texts(\u001b[43mpdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "output = '/home/tagore/repos/ai/data/exampe_debug_folder'\n",
    "input = '/home/tagore/repos/ai/data/example_data'\n",
    "chroma_db = '/home/tagore/repos/ai/data/example_database'\n",
    "test_extractor = te.TextExtractor(output, input)\n",
    "pdfs = test_extractor.get_pdf()\n",
    "test_extractor.extract_pdf_texts(pdfs[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s://github.com/enormandeau/ncbi_blast_tutorial.\\n\\nAbout\\nCrash course for NCBI blast tools\\n\\nTopics\\n\\nResources\\n\\nStars\\n\\nWatchers\\n\\nForks\\n\\nReleases\\n\\nFooter\\n\\nFooter navigation',\n",
       " \"archive. For example:\\n\\nAdd the bin folder from the extracted archive to your path. For example, add\\nthe following line to your ~/.bashrc file:\\n\\nAnd change the /PATH/TO part to the path where you have put the extracted\\narchive.\\n\\nExample sequences to use with the tutorial\\nIn order to test blast, you need a test fasta file. Use the following files\\nthat come with the tutorial:\\n\\nCreate blast database\\nThe different blast tools require a formatted database to search against. In\\norder to create the database, we use the makeblastdb tool:\\n\\nThis will create a list of files in the databases folder. These are all part\\nof the blast database.\\n\\nBlast\\nWe can now blast our sequences against the database. In this case, both our\\nquery sequences and database sequences are DNA sequences, so we use the\\nblastn tool:\\n\\nYou can use different output formats with the outmft option:\\n\\nBlast with parallel\\nIf you need to run your blasts faster (and who doesn't?), you can maximise\\nCPU usage with gnu parallel. You will\",\n",
       " 'can maximise\\nCPU usage with gnu parallel. You will find it at this\\nlink.\\n\\nDownload the archive, extract it (with tar xvfB parallel-latest.tar.bz2) and\\ninstall it with the following commands:\\n\\nWe can now use parallel to speed up blast:\\n\\nMore options and getting help\\nIf you need help to know the options and parameters you can pass blastn and\\nthe other blast+ utilities, use the --help option and pipe the output into\\nless, for example:\\n\\nNCBI blast tools cover more cases than DNA against DNA searches. For example,\\nyou can search a protein database with either DNA or protein sequences. Here is\\nan exhaustive list of the programs that come with the blast+ distribution:\\n\\nReferences\\nO. Tange (2011): GNU Parallel - The Command-Line Power Tool, ;login: The USENIX Magazine, February 2011:42-47.\\n\\nLicence\\nNCBI blast tutorial by Eric Normandeau is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.Based on a work at https://github.com/enormandeau/ncbi_blast_tutorial.\\n\\nA',\n",
       " 'Navigation Menu\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\n\\nSaved searches\\n\\nUse saved searches to filter your results more quickly\\nTo see all available qualifiers, see our documentation.\\n\\nCrash course for NCBI blast tools\\n\\nenormandeau/ncbi_blast_tutorial\\n\\nFolders and files\\n\\nLatest commit\\n\\nHistory\\n\\nRepository files navigation\\n\\nNCBI blast tutorial\\nShort introduction to using NCBI blast tools from the command line\\n\\nUsing Blast from the command line\\nSometimes, you may have to use blast on your own computer to query thousands of\\nsequences against a custom database of hundreds of thousands of sequences. To\\ndo that, you will need to install Blast on your computer, format the database,\\nand then blast the sequences.\\n\\nHere is a short tutorial on how to do this.\\n\\nInstalling Blast+ tools\\nGet the compiled executables from this URL:\\n\\nDecompress the archive. For example:\\n\\nAdd the bin folder from th']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urltext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database: Class Definition\n",
    "\n",
    "/home/tagore/repos/ai/scripts/VectorDB.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extractor: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tagore/repos/ai/scripts\")\n",
    "import TextExtractor as te\n",
    "import VectorDB as vdb\n",
    "\n",
    "\n",
    "input = '/home/tagore/repos/ai/data/example_data/'\n",
    "output = '/home/tagore/repos/ai/data/exampe_debug_folder'\n",
    "chroma_db = '/home/tagore/repos/ai/data/example_db/'\n",
    "collection_name = 'test'\n",
    "\n",
    "test_vector_db = vdb.VectorDB(input, output, chroma_db, collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vector_db.peek())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import ollama  # Ensure the Ollama library is imported\n",
    "import TextExtractor as te\n",
    "import VectorDB as vdb\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, input_dir: str, output_dir: str, chroma_db_dir: str, chroma_db_name: str, model=\"mxbai-embed-large\"):\n",
    "        self.vector_db = self._setup_vector_db(input_dir, output_dir, chroma_db_dir, chroma_db_name, model)\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    def _setup_vector_db(self, input_dir, output_dir, chroma_db_dir, chroma_db_name, model):\n",
    "        \"\"\"Check if the database exists and set up if not.\"\"\"\n",
    "        try:\n",
    "            # Attempt to load existing vector database\n",
    "            vector_db = vdb.VectorDB(input_dir, output_dir, chroma_db_dir, chroma_db_name, model)\n",
    "            # Check if the database is empty or needs updating\n",
    "            if not self._is_database_populated(vector_db):\n",
    "                logging.info(\"Database is not populated. Loading data...\")\n",
    "                vector_db.load_data()\n",
    "            return vector_db\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error setting up VectorDB: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _is_database_populated(self, vector_db):\n",
    "        \"\"\"Check if the vector database has data.\"\"\"\n",
    "        return len(vector_db.peek()) > 0\n",
    "    \n",
    "    def generate_prompt(self, question, context):\n",
    "        template = \"\"\"You need to answer questions about specific software.\n",
    "        Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "        keep the answer concise.\n",
    "        user\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Do not say according to the text. just give the answer, no comment.\"\"\"\n",
    "        return template.format(question=question, context=context)\n",
    "\n",
    "    def generate_answer(self, query_text, k=4):\n",
    "        \"\"\"Generate an answer using the vector database and Ollama model.\"\"\"\n",
    "        try:\n",
    "            output = ollama.generate(\n",
    "                    model=\"llama3\",\n",
    "                    prompt= self.generate_prompt(query_text, self.vector_db.query(query_text, k)),\n",
    "                )\n",
    "            return output['response']\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating answer: {e}\")\n",
    "            return \"Error generating answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '/home/tagore/repos/ai/data/example_data/'\n",
    "output = '/home/tagore/repos/ai/data/exampe_debug_folder'\n",
    "chroma_db = '/home/tagore/repos/ai/data/example_db/'\n",
    "collection_name = 'test'\n",
    "\n",
    "testRAG = RAG(input, output, chroma_db, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word size parameter in BLAST refers to the size of words that can score at least T when compared with words from the query, and is valid for values between 2-7.\n"
     ]
    }
   ],
   "source": [
    "print(testRAG.generate_answer(\"What does word size parameter mean in BLAST?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get the results of BLASTP in XML format, you can use the `blast_formatter` command with the `-outfmt 5` option, as shown in the example: `$ blast_formatter –rid X3R7GAUS014 –out test.xml –outfmt 5`\n"
     ]
    }
   ],
   "source": [
    "print(testRAG.generate_answer(\"How to get the results of BLASTP in XML format?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To perform a BLAST on a specific taxonomic group, you can use the `-taxids` option and specify the NCBI taxonomy ID(s) for the given organism(s). For example: `$ blastn –db nt –query QUERY –taxids 9606 –outfmt 7 –out OUTPUT.tab`.\n"
     ]
    }
   ],
   "source": [
    "print(testRAG.generate_answer(\"How to perform a BLAST on a specific taxonomic group?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the \"word_size\" parameter and set it to 2 or less, as epitopes smaller than 10 amino acids are likely to be shorter sequences.\n"
     ]
    }
   ],
   "source": [
    "print(testRAG.generate_answer(\"What parameters do I use to perform BLAST with epitopes smaller than 10 amino acids?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein databases (e.g., PDB, GenBank) and nucleotide databases (e.g., nt, nr).\n"
     ]
    }
   ],
   "source": [
    "print(testRAG.generate_answer(\"Which kind of databases can be searched with BLASTX?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
