{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction & Data Base Embeddings Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tagore/repos/ai/scripts\")\n",
    "import TextExtractor as te\n",
    "import VectorDB as vdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extractor: Class Definition\n",
    "\n",
    "/scripts/TextExtractor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extractor: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m test_extractor \u001b[38;5;241m=\u001b[39m te\u001b[38;5;241m.\u001b[39mTextExtractor(output, \u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      5\u001b[0m pdfs \u001b[38;5;241m=\u001b[39m test_extractor\u001b[38;5;241m.\u001b[39mget_pdf()\n\u001b[0;32m----> 6\u001b[0m test_extractor\u001b[38;5;241m.\u001b[39mextract_pdf_texts(\u001b[43mpdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "output = '/home/tagore/repos/ai/data/exampe_debug_folder'\n",
    "input = '/home/tagore/repos/ai/data/example_data'\n",
    "chroma_db = '/home/tagore/repos/ai/data/example_database'\n",
    "test_extractor = te.TextExtractor(output, input)\n",
    "pdfs = test_extractor.get_pdf()\n",
    "test_extractor.extract_pdf_texts(pdfs[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s://github.com/enormandeau/ncbi_blast_tutorial.\\n\\nAbout\\nCrash course for NCBI blast tools\\n\\nTopics\\n\\nResources\\n\\nStars\\n\\nWatchers\\n\\nForks\\n\\nReleases\\n\\nFooter\\n\\nFooter navigation',\n",
       " \"archive. For example:\\n\\nAdd the bin folder from the extracted archive to your path. For example, add\\nthe following line to your ~/.bashrc file:\\n\\nAnd change the /PATH/TO part to the path where you have put the extracted\\narchive.\\n\\nExample sequences to use with the tutorial\\nIn order to test blast, you need a test fasta file. Use the following files\\nthat come with the tutorial:\\n\\nCreate blast database\\nThe different blast tools require a formatted database to search against. In\\norder to create the database, we use the makeblastdb tool:\\n\\nThis will create a list of files in the databases folder. These are all part\\nof the blast database.\\n\\nBlast\\nWe can now blast our sequences against the database. In this case, both our\\nquery sequences and database sequences are DNA sequences, so we use the\\nblastn tool:\\n\\nYou can use different output formats with the outmft option:\\n\\nBlast with parallel\\nIf you need to run your blasts faster (and who doesn't?), you can maximise\\nCPU usage with gnu parallel. You will\",\n",
       " 'can maximise\\nCPU usage with gnu parallel. You will find it at this\\nlink.\\n\\nDownload the archive, extract it (with tar xvfB parallel-latest.tar.bz2) and\\ninstall it with the following commands:\\n\\nWe can now use parallel to speed up blast:\\n\\nMore options and getting help\\nIf you need help to know the options and parameters you can pass blastn and\\nthe other blast+ utilities, use the --help option and pipe the output into\\nless, for example:\\n\\nNCBI blast tools cover more cases than DNA against DNA searches. For example,\\nyou can search a protein database with either DNA or protein sequences. Here is\\nan exhaustive list of the programs that come with the blast+ distribution:\\n\\nReferences\\nO. Tange (2011): GNU Parallel - The Command-Line Power Tool, ;login: The USENIX Magazine, February 2011:42-47.\\n\\nLicence\\nNCBI blast tutorial by Eric Normandeau is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.Based on a work at https://github.com/enormandeau/ncbi_blast_tutorial.\\n\\nA',\n",
       " 'Navigation Menu\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\n\\nSaved searches\\n\\nUse saved searches to filter your results more quickly\\nTo see all available qualifiers, see our documentation.\\n\\nCrash course for NCBI blast tools\\n\\nenormandeau/ncbi_blast_tutorial\\n\\nFolders and files\\n\\nLatest commit\\n\\nHistory\\n\\nRepository files navigation\\n\\nNCBI blast tutorial\\nShort introduction to using NCBI blast tools from the command line\\n\\nUsing Blast from the command line\\nSometimes, you may have to use blast on your own computer to query thousands of\\nsequences against a custom database of hundreds of thousands of sequences. To\\ndo that, you will need to install Blast on your computer, format the database,\\nand then blast the sequences.\\n\\nHere is a short tutorial on how to do this.\\n\\nInstalling Blast+ tools\\nGet the compiled executables from this URL:\\n\\nDecompress the archive. For example:\\n\\nAdd the bin folder from th']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urltext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database: Class Definition\n",
    "\n",
    "/home/tagore/repos/ai/scripts/VectorDB.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extractor: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tagore/repos/ai/scripts\")\n",
    "import TextExtractor as te\n",
    "import VectorDB as vdb\n",
    "\n",
    "\n",
    "input = '/home/tagore/repos/ai/data/example_data/'\n",
    "output = '/home/tagore/repos/ai/data/exampe_debug_folder'\n",
    "chroma_db = '/home/tagore/repos/ai/data/example_db/'\n",
    "collection_name = 'test'\n",
    "\n",
    "test_vector_db = vdb.VectorDB(input, output, chroma_db, collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: d02872bef51892a4b7bb3dfba3a73790\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 50ff8a4d76d26deab371744f55b42c2c\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: d02872bef51892a4b7bb3dfba3a73790\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 50ff8a4d76d26deab371744f55b42c2c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ize of the PIR\\ndatabase and the length of an average protein.)\\nAs seen from Table 1, only MSPs with a score over 55\\nare likely to be distinguishable from chance similarities.\\nWith w = 4 and T = 17,\\nBLAST should miss only about a fifth of the MSPs with this score,\\nand only about a tenth of MSPs with a score near 70.\\nWe will consider below the algorithm’s performance on real data.\\n\\n(b) The choice of word length and threshold parameters\\n\\nOn what basis do we choose the particular setting of the parameters\\nw and T for executing BLAST on real data?\\nWe begin by considering the word length w.\\n\\nThe time required to execute BLAST is the sum of the times required\\n(1) to compile a list of words that can score at least T\\nwhen compared with words from the query;\\n(2) to scan the database for hits (i.e. matches to words\\non this list);\\nand (3) to extend all hits to seek segment pairs with scores\\nexceeding the cutoff.\\nThe time for the last of these tasks is proportional to the\\nnumber of hits, which clea',\n",
       " 'aW + bN + cNW/20w,\\nwhere W is the number of words generated,\\nN is the number of residues in the database and\\na, b and c are constants.\\nThe W term accounts for compiling the word list,\\nthe N term covers the database scan,\\nand the NW term is for extending the hits.\\nAlthough the number of words generated, W,\\nincreases exponentially with decreasing T,\\nit increases only linearly with the length of the query,\\nso that doubling the query length doubles the number of words.\\nWe have found in practice that T = 17 is a good choice for the\\nthreshold because, as discussed below,\\nlowering the parameter further provides little improvement\\nin the detection of actual homologies.\\n\\nBLAST’s direct tradeoff between accuracy and speed is best illustrated\\nby Table 2.\\nGiven a specific probability q of missing a chance MSP with score S,\\none can calculate what threshold parameter T is required,\\nand therefore the approximate execution time.\\nCombining the data of Table 1 and Figure 2,\\nTable 2 shows the central pro',\n",
       " 'BLAST (biotechnology)/wiki/CRAM (file format)\\nOther reasons this message may be displayed:',\n",
       " 'ough reducing the threshold T improves the approximation of MSP\\nscores by BLAST,\\nit also increases execution time because there will be more words\\ngenerated by the query sequence and therefore more hits.\\nWhat value of T provides a reasonable compromise\\nbetween the considerations of sensitivity and time?\\nTo provide numerical data, we compared a random 250 residue sequence\\nagainst the entire PIR database (Release 23.0, 14,372 entries\\nand 3,977,903 residues) with T ranging from 20 to 13.\\nIn Figure 2 we plot the execution time\\n(user time on a SUN4-280) versus the number of words generated\\nfor each value of T.\\nAlthough there is a linear relationship between the number of words\\ngenerated and execution time,\\nthe number of words generated increases exponentially with decreasing T\\nover this range (as seen by the spacing of x values).\\nThis plot and a simple analysis reveal that the expected-time\\ncomputational complexity of BLAST is approximately\\naW + bN + cNW/20w,\\nwhere W is the number of words',\n",
       " 'BLAST (biotechnology)/wiki/FASTQ format\\nOther reasons this message may be displayed:']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector_db.query(\"What is word size parameter in BLAST? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
