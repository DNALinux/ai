{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tagore/repos/ai/scripts\")\n",
    "import os\n",
    "import time\n",
    "import ollama\n",
    "import chromadb\n",
    "import torch\n",
    "import h5py\n",
    "from torch  import cuda\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import generate_embeddings as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_directory = '/home/tagore/repos/ai/data/processed/texts/Bookshelf_NBK279690.pdf'\n",
    "collection_name = \"blast_db_unprocessed\"\n",
    "database_file = '/home/tagore/repos/ai/data/processed/embeddings/chrome_db_unprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=database_file)\n",
    "collection = client.get_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_dna_questions = [\"What is word size parameter in BLAST?\",\n",
    "\"How to get the results of BLASTP in XML format?\",\n",
    "\"How to perform a BLAST on a specific taxonomic group?\",\n",
    "\"What parameters do I use to perform BLAST with epitopes smaller than 10 amino acids?\",\n",
    "\"Which kind of databases can be searched with BLASTX?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Table continued from previous page.\\nBLAST_USAGE_REPORT Specifies  whether or not usage information should be returned to the NCBI. Set this variable \\nto false to disable this feature.\\nControlling concatenation of queries\\nAs described above, BLAST+ works more efficiently  if it scans the database once for multiple queries. This \\nfeature is knows as concatenation. Unfortunately, for some searches the concatenation values are not optimal, \\ntoo many queries are searched at once, and the process can consume too much memory. For applications besides \\nBLASTN (which uses an adaptive approach), it is possible to control these values by setting the BATCH_SIZE \\nenvironment variable. Setting the value too low will degrade performance dramatically, so this environment \\nvariable should be used with caution.\\nMemory usage\\nThe BLAST search programs can exhaust all memory on a machine if the input is too large or if there are too \\nmany hits to the BLAST database. If this is the case, please see your operating system documentation to limit the \\nmemory used by a program (e.g.: ulimit on Unix-like platforms). Setting the BATCH_SIZE environment \\nvariable as described above may help.Configuring  BLAST 25',\n",
       " 'Table continued from previous page.\\ndb_length Length (size) of the database in letters (bases or amino acid characters)\\ndb_name BLAST database name\\ndb_num_seqs Number of sequences in the BLAST database.\\nevalue_threshold Expect value limit.\\nSee Command-line options\\nexit_status BLAST program exit status. The value ‘0’ indicates success.\\nSee the Exit codes  in the manual for more information.\\nhitlist_size Number of matches to return. This  is the same value as the max_target_seqs option.\\nSee Command-line options  in the manual.\\nncbi_app Parameter used by NCBI application logging. All BLAST programs return ‘standalone-blast’\\nncbi_location Default parameter for BLAST. Value always ‘be-me for (Bethesda, Maryland)\\nncbi_role Default parameter. Value always production.\\nnum_queries Number of query sequences in the BLAST search.\\nOpt-out of Usage Reporting\\nY ou can opt-out of the usage reporting by adding a .ncbirc (UNIX like) or ncbi.ini (Windows) configuration  file. \\nIn the configuration  file you should add a line under the BLAST section to set BLAST_USAGE_REPORT to \\nfalse. See\\xa0 here  for details on setting up a configuration  file.\\nY ou may also opt-out of the usage reporting by setting the environment variable BLAST_USAGE_REPORT to \\nfalse. In bash (under LINUX) this command would be:\\nexport BLAST_USAGE_REPORT=false\\nNote that this environment variable is only set in the shell (i.e., window) you are currently using and will not be \\nset the next time you login. To permanently opt-out, this variable should be set every time a new shell is opened \\nor with a configuration  file, as described above.\\nY ou can also set this environment variable, turning off usage reporting, when using BLAST+ docker by adding \\nthe -e option to your docker invocation:\\n-e BLAST_USAGE_REPORT=false\\nThe NLM privacy policy is available\\xa0 here .12 BLAST® Command Line Applications User Manual',\n",
       " \"Table C1 continued from previous page.\\noption type default value description and notes\\nstitle means Subject Title\\nsalltitles means All Subject Title(s), separated by a '<>'\\nsstrand means Subject Strand\\nqcovs means Query Coverage Per Subject (for all HSPs)\\nqcovhsp means Query Coverage Per HSP\\nqcovus is a measure of Query Coverage that counts a position in a subject sequence \\nfor this measure only once. The second time the position is aligned to the query is not \\ncounted towards this measure.\\nWhen not provided, the default value is:\\n'qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue \\nbitscore', which is equivalent to the keyword 'std'\\nTable C2: blastn application options. The blastn application searches a nucleotide query against nucleotide subject sequences or a \\nnucleotide database. An option of type “flag”  takes no arguments, but if present the argument is true. Four different  tasks are \\nsupported: 1.) “megablast” , for very similar sequences (e.g, sequencing errors), 2.) “dc-megablast” , typically used for inter-species \\ncomparisons, 3.) “blastn” , the traditional program used for inter-species comparisons, 4.) “blastn-short” , optimized for sequences less \\nthan 30 nucleotides.\\noption task(s) type default value description and notes\\nword_size megablast integer 28 Length of initial exact match.\\nword_size dc-megablast integer 11 Number of matching nucleotides in initial match. dc-\\nmegablast allows non-consecutive letters to match.\\nword_size blastn integer 11 Length of initial exact match.\\nword_size blastn-short integer 7 Length of initial exact match.\\ngapopen megablast integer 0 Cost to open a gap. See appendix “BLASTN reward/penalty \\nvalues” .\\ngapextend megablast integer none Cost to extend a gap. This  default is a function of reward/\\npenalty value. See appendix “BLASTN reward/penalty \\nvalues” .\\ngapopen blastn, blastn-short, \\ndc-megablastinteger 5 Cost to open a gap. See appendix “BLASTN reward/penalty \\nvalues” .\\ngapextend blastn, blastn-short, \\ndc-megablastinteger 2 Cost to extend a gap. See appendix “BLASTN reward/penalty \\nvalues” .80 BLAST® Command Line Applications User Manual\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example prompt\n",
    "prompt = blast_dna_questions[0]\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"mxbai-embed-large\"\n",
    ")\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "  n_results=3\n",
    ")\n",
    "data = results['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(question, context):\n",
    "    template = \"\"\"You need to give instructions on how we can use specific software.\n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    keep the answer concise.\n",
    "    user\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Do not say according to the text. just give the answer, no comment.\"\"\"\n",
    "    return template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word size parameter in BLAST is an integer that represents the length of initial exact match. Its default value varies depending on the task:\n",
      "\n",
      "* megablast: 28\n",
      "* dc-megablast: 11\n",
      "* blastn: 11\n",
      "* blastn-short: 7\n"
     ]
    }
   ],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "output = ollama.generate(\n",
    "  model=\"llama3\",\n",
    "  prompt=generate_prompt(prompt, data)\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      5\u001b[0m em \u001b[38;5;241m=\u001b[39m ge\u001b[38;5;241m.\u001b[39mget_embeddings(prompt[\u001b[38;5;241m4\u001b[39m], model, tokenizer)\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcollection3\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m      7\u001b[0m   query_embeddings\u001b[38;5;241m=\u001b[39mem\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      8\u001b[0m   n_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collection3' is not defined"
     ]
    }
   ],
   "source": [
    "model_name=\"dmis-lab/biobert-base-cased-v1.2\"\n",
    "# Initialize BioBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "em = ge.get_embeddings(prompt[4], model, tokenizer)\n",
    "results = collection3.query(\n",
    "  query_embeddings=em.tolist(),\n",
    "  n_results=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toyokoserver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
