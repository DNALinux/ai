{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tagore/repos/ai/scripts\")\n",
    "import os\n",
    "import time\n",
    "import ollama\n",
    "import chromadb\n",
    "import torch\n",
    "import h5py\n",
    "from torch  import cuda\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import generate_embeddings as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_directory = '/home/tagore/repos/ai/data/processed/texts/Bookshelf_NBK279690.pdf'\n",
    "collection_name = \"blast_db_unprocessed\"\n",
    "database_file = '/home/tagore/repos/ai/data/processed/embeddings/chrome_db_unprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=database_file)\n",
    "collection = client.get_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_dna_questions = [\"What is word size parameter in BLAST?\",\n",
    "\"How to get the results of BLASTP in XML format?\",\n",
    "\"How to perform a BLAST on a specific taxonomic group?\",\n",
    "\"What parameters do I use to perform BLAST with epitopes smaller than 10 amino acids?\",\n",
    "\"Which kind of databases can be searched with BLASTX?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Functionality offered by BLAST+ applications\\nTom Madden1\\nCreated: June 23, 2008; Updated: September 25, 2020.\\nThe functionality offered  by the BLAST+ applications has been organized by program type, as to more closely \\nresemble Web BLAST.\\nAs an example, to run a search of a nucleotide query (translated “on the fly” by BLAST) against a protein \\ndatabase one would use the blastx application. The blastx application will also work in “Blast2Sequences” mode \\n(i.e.: accept FASTA sequences instead of a BLAST database as targets) and can also send BLAST searches over \\nthe network to the public NCBI server if desired.\\nThe BLAST+ package offers  three categories of applications: 1.) search tools, 2.) BLAST database tools, and 3.) \\nsequence filtering  tools. The blastn, blastp, blastx, tblastx, tblastn, psiblast, rpsblast, and rpstblastn are considered \\nsearch applications, as they execute a BLAST search, whereas makeblastdb, blastdb_aliastool, makeprofiledb,  and \\nblastdbcmd are considered BLAST database applications, as they either create or examine BLAST databases.\\nThere  is also a new set of sequence filtering  applications described in the section Sequence filtering  applications \\nand an application to build database indices that greatly speed up megablast in some cases (see section titled \\nMegablast indexed searches ).\\nAuthor Affiliation:  1 Email: madden@ncbi.nlm.nih.gov15',\n",
       " 'suite accepts a large number of options; try running blastn -help to see them for the blastn program. Here is a summary of a few parameters that are most commonly used for blastn et al.:\\n\\nBLAST Databases\\nNo doubt readers familiar with BLAST have been curious: aren’t there databases of some kind involved in BLAST searches? Not necessarily. As we’ve seen, simple FASTA files will suffice for both the query and subject set. It turns out, however, that from a computational perspective, simple FASTA files are not easily searched. Thus BLAST+ provides a tool called makeblastdb that converts a subject FASTA file into an indexed and quickly searchable (but not human-readable) version of the same information, stored in a set of similarly named files (often at least three ending in .pin, .psq, and .phr for protein sequences, and .nin, .nsq, and .nhr for nucleotide sequences). This set of files represents the “database,” and the database name is the shared file name prefix of these files.\\n\\nRunning makeblastdb on a FASTA file is fairly simple: makeblastdb -in <fasta file> -out <database name> -dbtype <type> -title <title> -parse_seqids, where <type> is one of prot or nucl, and <title> is a human-readable title (enclosed in quotes if necessary). The -parse_seqids flag indicates that the sequence IDs from the FASTA file should be included in the database so that they can be used in outputs as well as by other tools like blastdbcmd (discussed below).\\n\\nOnce a BLAST database has been created,',\n",
       " 'below).\\n\\nOnce a BLAST database has been created, other options can be used with blastn et al.:\\n\\nWhen using the -db option, the BLAST tools will search for the database files in three locations: (1) the present working directory, (2) your home directory, and (3) the paths specified in the $BLASTDB environment variable.\\n\\nThe tool blastdbcmd can be used to get information about BLAST databases—for example, with blastdbcmd -db <database name> -info—and can show the databases in a given path with blastdbcmd -list <path> (so, blastdbcmd -list $BLASTDB will show the databases found in the default search paths). This tool can also be used to extract sequences or information about them from databases based on information like the IDs reported in output files. As always, reading the help and documentation for software like BLAST is highly recommended.\\n\\nRunning a Self-BLAST\\nTo put these various tools and options to use, let’s consider using blastp to look for proteins that are similar in sequence to other proteins in the yeast exome. First, we’ll need to use wget to download the protein data set (after locating it at http://yeastgenome.org), and then gzip -d to decompress it, calling it orf_trans.fasta.\\n\\nIn order to find sequences that are similar to others, we’re going to want to blastp this file against itself. So, we’ll start by creating a database of these sequences.\\n\\nNow we need to determine what options we will use for the blastp. In particular, do we want to limit the number of']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example prompt\n",
    "prompt = blast_dna_questions[4]\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"mxbai-embed-large\"\n",
    ")\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "  n_results=3\n",
    ")\n",
    "data = results['documents'][0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein databases can be searched with BLASTX.\n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(question, context):\n",
    "        template = \"\"\"You need to answer questions about specific software.\n",
    "        Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "        keep the answer concise.\n",
    "        user\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Do not say according to the text. just give the answer, no comment.\"\"\"\n",
    "        return template.format(question=question, context=context)\n",
    "\n",
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "output = ollama.generate(\n",
    "  model=\"llama3\",\n",
    "  prompt=generate_prompt(prompt, data)\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record the answer after we have add URL data into the database\n",
    "\n",
    "#### Q: What is word size parameter in BLAST?\n",
    "\n",
    "A: \n",
    "The word size parameter in BLAST is an integer that represents the length of initial exact match. Its default value varies depending on the task:\n",
    "\n",
    "* megablast: 28\n",
    "* dc-megablast: 11\n",
    "* blastn: 11\n",
    "* blastn-short: 7\n",
    "\n",
    "#### Q:How to get the results of BLASTP in XML format?\n",
    "\n",
    "A:\n",
    "To get the results of BLASTP in XML format, use:\n",
    "\n",
    "$ blast_formatter –rid X3R7GAUS014 –out test.xml –outfmt \"XML\"\n",
    "\n",
    "\n",
    "#### Q: How to perform a BLAST on a specific taxonomic group?\n",
    "\n",
    "A:\n",
    "To perform a BLAST on a specific taxonomic group, you can use the following command:\n",
    "\n",
    "`blastn –db nt –query QUERY –taxids 9606 –outfmt 7 –out OUTPUT.tab`\n",
    "\n",
    "Replace `QUERY` with your query sequence file, `OUTPUT.tab` with your desired output file name, and `9606` with the taxonomy ID(s) of the specific taxonomic group you want to search.\n",
    "\n",
    "#### Q:What parameters do I use to perform BLAST with epitopes smaller than 10 amino acids?\n",
    "\n",
    "A:\n",
    "To perform BLAST with epitopes smaller than 10 amino acids, you can use the \"word_size\" parameter and set it to a value between 2-7. The default value is 3 for standard protein-protein comparisons. \n",
    "\n",
    "For shorter query sequences, you may want to consider using the \"blastp-short\" task or increasing the word size to capture smaller epitopes.\n",
    "\n",
    "#### Q:Which kind of databases can be searched with BLASTX?\n",
    "\n",
    "A:\n",
    "Protein databases can be searched with BLASTX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      5\u001b[0m em \u001b[38;5;241m=\u001b[39m ge\u001b[38;5;241m.\u001b[39mget_embeddings(prompt[\u001b[38;5;241m4\u001b[39m], model, tokenizer)\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcollection3\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m      7\u001b[0m   query_embeddings\u001b[38;5;241m=\u001b[39mem\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      8\u001b[0m   n_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collection3' is not defined"
     ]
    }
   ],
   "source": [
    "model_name=\"dmis-lab/biobert-base-cased-v1.2\"\n",
    "# Initialize BioBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "em = ge.get_embeddings(prompt[4], model, tokenizer)\n",
    "results = collection3.query(\n",
    "  query_embeddings=em.tolist(),\n",
    "  n_results=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toyokoserver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
